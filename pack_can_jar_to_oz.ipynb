{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import concurrent.futures\n",
    "\n",
    "ing=pd.read_csv(\"/Users/osman/Desktop/Master Project/data/2/recipe40k.csv\")\n",
    "#SOME PREPROCESSING ARE ONGOING:\n",
    "\n",
    "#delete recipes that have more than one URL\n",
    "ing = ing.groupby(\"recipe\").filter(lambda x: len(x[\"URL\"].unique()) == 1)\n",
    "\n",
    "#the data was wrong in respect of black bean. It turned out that, almost all black peppers in can unit were actually black beans. \n",
    "#same story for green been.\n",
    "ing.loc[(ing.ingredientName == 'black pepper') & (ing.ingredientUnit == 'can'), 'ingredientName'] = 'black bean'\n",
    "ing.loc[(ing.ingredientName == 'green pepper') & (ing.ingredientUnit == 'can'), 'ingredientName'] = 'green bean'\n",
    "ing.loc[(ing.ingredientName == 'onion') & (ing.ingredientUnit == 'bunch'), 'ingredientName'] = 'green onion'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packcanjar FUNCTION\n",
    "#for all \"can\", \"package\" and \"jar\" ingredient units, it goes to corresponding URL and scrape the ounce version of the ingredient.\n",
    "#In summary, all the ingredients in \"can\", \"package\" and \"jar\"  units are converted to \"ounce\" unit.\n",
    "\n",
    "\n",
    "\n",
    "#18k rows of data includes \"can\", \"package\" and \"jar\" units:\n",
    "package=ing[(ing.ingredientUnit==\"package\") |  (ing.ingredientUnit==\"can\")|(ing.ingredientUnit==\"jar\")].reset_index(drop=True)\n",
    "\n",
    "# Function to scrape ingredient quantities from a single URL\n",
    "def scrape_single_url(url, ingredient_name):\n",
    "    data = []\n",
    "\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Find all ingredient items on the page\n",
    "    ingredients = soup.find_all(\"span\", {\"data-ingredient-name\": True})\n",
    "\n",
    "    for ingredient in ingredients:\n",
    "        ingredient_text = ingredient.get_text(\"data-ingredient-name\")\n",
    "\n",
    "        # Check if \"package\" is in the previous span element with \"data-ingredient-unit\" attribute\n",
    "        previous_span = ingredient.find_previous(\"span\", {\"data-ingredient-unit\": True})\n",
    "        if previous_span:\n",
    "            previous_unit_text = previous_span.get_text()\n",
    "        else:\n",
    "            previous_unit_text = \"\"\n",
    "\n",
    "\n",
    "        if ingredient_name in ingredient_text and \"can\" in previous_unit_text:\n",
    "            # Find the quantity associated with the ingredient (if available)\n",
    "            quantity_span = ingredient.find_previous(\"span\", {\"data-ingredient-unit\": True})\n",
    "            if quantity_span:\n",
    "                quantity = re.search(r'\\d+(\\.\\d+)?', quantity_span.get_text()).group() if quantity_span else \"N/A\"\n",
    "            else:\n",
    "                quantity = \"N/A\"\n",
    "            data.append([url, ingredient_name, quantity])\n",
    "        elif ingredient_name in ingredient_text and \"package\" in previous_unit_text:\n",
    "            # Find the quantity associated with the ingredient (if available)\n",
    "            quantity_span = ingredient.find_previous(\"span\", {\"data-ingredient-unit\": True})\n",
    "            if quantity_span:\n",
    "                quantity = re.search(r'\\d+(\\.\\d+)?', quantity_span.get_text()).group() if quantity_span else \"N/A\"\n",
    "            else:\n",
    "                quantity = \"N/A\"\n",
    "            data.append([url, ingredient_name, quantity])\n",
    "        \n",
    "        elif ingredient_name in ingredient_text and \"jar\" in previous_unit_text:\n",
    "            # Find the quantity associated with the ingredient (if available)\n",
    "            quantity_span = ingredient.find_previous(\"span\", {\"data-ingredient-unit\": True})\n",
    "            if quantity_span:\n",
    "                quantity = re.search(r'\\d+(\\.\\d+)?', quantity_span.get_text()).group() if quantity_span else \"N/A\"\n",
    "            else:\n",
    "                quantity = \"N/A\"\n",
    "            data.append([url, ingredient_name, quantity])\n",
    "        \n",
    "        else:\n",
    "            quantity = \"N/A\"  # Set a default value for cases where the unit or ingredient_name is not found\n",
    "        data.append([url, ingredient_name, quantity])\n",
    "\n",
    "    if not data:\n",
    "        data = [[url, ingredient_name, \"N/A\"]]  # Add a default entry if no matches found\n",
    "\n",
    "    return data\n",
    "\n",
    "# Function to scrape ingredient quantities from multiple recipe URLs in parallel\n",
    "def scrape_ingredient_quantities_parallel(df, max_workers=16):\n",
    "    data = []\n",
    "    urls = df['URL']\n",
    "    ingredient_names = df['ingredientName']\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(scrape_single_url, urls, ingredient_names))\n",
    "\n",
    "    for result in results:\n",
    "        data.extend(result)\n",
    "\n",
    "    # Create a DataFrame from the list of data\n",
    "    df = pd.DataFrame(data, columns=['URL', 'ingredientName', 'ingredientQuantity'])\n",
    "    #convert to float\n",
    "    df.ingredientQuantity=df.ingredientQuantity.apply(convert_to_float)\n",
    "    \n",
    "    #same ingredients are summed \n",
    "    df=df.groupby([\"URL\",\"ingredientName\"])['ingredientQuantity'].sum().reset_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "packcanjar_oz = scrape_ingredient_quantities_parallel(package)\n",
    "packcanjar_oz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packcanjar_oz.to_csv(\"/Users/osman/Desktop/Master Project/data/2/packcanjar_oz.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
